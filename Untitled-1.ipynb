{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_images/msg-1002053127537-16.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files_in_directory(directory_path):\n",
    "    file_paths = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            # Get the full path of the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Append the file path to the list\n",
    "            file_paths.append( file_path)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"raw_images\"\n",
    "files_list = list_files_in_directory(directory_path)\n",
    "\n",
    "print((files_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models..\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Define a function to load YOLO models during initialization\n",
    "card_model = None\n",
    "flipping_model = None\n",
    "\n",
    "\n",
    "model_lock = threading.Lock()\n",
    "\n",
    "print(\"Initializing models..\")\n",
    "\n",
    "with model_lock:\n",
    "    if card_model is None:\n",
    "        card_model = YOLO('./models/Card_Finder.pt', verbose=False)\n",
    "    if flipping_model is None:\n",
    "        flipping_model = YOLO('./models/Flipping_Model.pt', verbose=False)\n",
    "\n",
    "def get_card_vertices(src, model):\n",
    "\n",
    "    \"\"\"\n",
    "    The function get the vertices of the card in the image ordered in clockwise order.\n",
    "\n",
    "    Parameters:\n",
    "        src (MatLike): The src image.\n",
    "\n",
    "    Returns:\n",
    "        vertices : the vertices of the card ordered in clockwise order,  in case of there is no card the output will be (None).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ordered_corners = None\n",
    "\n",
    "    results = model(src)    \n",
    "\n",
    "    # print(results)\n",
    "\n",
    "    if results[0].masks is None:\n",
    "        return ordered_corners\n",
    "\n",
    "    mask = results[0].masks.data[0]\n",
    "    # Convert to binary for segmentation\n",
    "    binary_mask = (mask.cpu().numpy() > 0.5).astype(np.uint8) * 255\n",
    "    # Resize the binary mask to match the original image dimensions\n",
    "    binary_mask = cv2.resize(binary_mask, (src.shape[1], src.shape[0]))\n",
    "\n",
    "    # add extra area to contour\n",
    "    binary_mask = cv2.dilate(binary_mask, np.ones((10, 10), np.uint8), iterations=1)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assuming the largest contour is the ID card\n",
    "    card_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Find corners of the card\n",
    "    epsilon = 0.05 * cv2.arcLength(card_contour, True)\n",
    "    approx = cv2.approxPolyDP(card_contour, epsilon, True)\n",
    "\n",
    "    # Reorder the points to ensure they are in clockwise order\n",
    "    corners = np.array(approx).reshape(-1, 2)\n",
    "    ordered_corners = np.zeros_like(corners)\n",
    "\n",
    "    # Calculate the centroid of the points\n",
    "    centroid = np.mean(corners, axis=0)\n",
    "\n",
    "    # Sort the points based on their angle from the centroid\n",
    "    angles = np.arctan2(corners[:, 1] - centroid[1], corners[:, 0] - centroid[0])\n",
    "    sorted_indices = np.argsort(angles)\n",
    "\n",
    "    # Reorder the corners\n",
    "    for i in range(4):\n",
    "        ordered_corners[i] = corners[sorted_indices[i]]\n",
    "\n",
    "    return ordered_corners\n",
    "\n",
    "\n",
    "def crop_vertices(src, vertices, out_size):\n",
    "\n",
    "    \"\"\"\n",
    "    This function crop card in horizontal.\n",
    "\n",
    "    Parameters:\n",
    "        src (MatLike): The src image.\n",
    "\n",
    "    Returns:\n",
    "        card (MatLike) : The cropped card image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Reorder the vertices so that it starts with the longest side\n",
    "\n",
    "        # Calculate the lengths of the four sides of the quadrilateral\n",
    "    side_lengths = []\n",
    "    for i in range(4):\n",
    "        x1, y1 = vertices[i]\n",
    "        x2, y2 = vertices[(i + 1) % 4]\n",
    "        side_length = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        side_lengths.append(side_length)\n",
    "\n",
    "        # Find the index of the longest side\n",
    "    longest_side_index = side_lengths.index(max(side_lengths))\n",
    "\n",
    "    reordered_vertices = np.roll(vertices, -longest_side_index, axis=0)\n",
    "\n",
    "    # Perspective RATIO MODIFYING\n",
    "\n",
    "    dst_corners = np.array([[0, 0], [out_size[0] - 1, 0], [out_size[0] - 1, out_size[1] - 1], [0, out_size[1] - 1]], dtype='float32')\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(reordered_vertices.astype('float32'), dst_corners)\n",
    "\n",
    "        # Apply the perspective transformation\n",
    "        result = cv2.warpPerspective(src, M, out_size)\n",
    "\n",
    "        return result\n",
    "\n",
    "    except:\n",
    "        return src\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crop_card(src):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes image for front or back side of national id card then return with cropped national id card with fixed size.\n",
    "\n",
    "    Parameters:\n",
    "        src (MatLike): The src image.\n",
    "\n",
    "    Returns:\n",
    "        card (MatLike) : The cropped card image, in case of there is no card the output will be (None).\n",
    "    \"\"\"\n",
    "\n",
    "    # get the coordinates of the quadrilateral card card_vertices\n",
    "    card_vertices = get_card_vertices(src, model= card_model)\n",
    "    if card_vertices is None:\n",
    "        return src\n",
    "\n",
    "    # crop card and put it in the standard size\n",
    "    card_img = crop_vertices(src, card_vertices, out_size= (840, 530))\n",
    "    return card_img\n",
    "\n",
    "    \n",
    "def card_flipper(img):\n",
    "    # Perform inference\n",
    "    results = flipping_model(img)\n",
    "    boxes = results[0].boxes.xywh# Assuming the boxes are in xywh format\n",
    "    classes = results[0].boxes.cls\n",
    "    x_coords_with_classes = [ (box[0], flipping_model.names[int(c)]) for box, c in zip(boxes, classes) ]\n",
    "    \n",
    "    # Sort this list based on the x-coordinate\n",
    "    sorted_classes = [ cls for _, cls in sorted(x_coords_with_classes, key=lambda x: x[0]) ]\n",
    "    \n",
    "    if sorted_classes == []:\n",
    "        return img\n",
    "    if sorted_classes[0] =='n-b' or sorted_classes[0] == 'n-f' :\n",
    "        return img\n",
    "    else:\n",
    "        img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        return img\n",
    "\n",
    "def create_directory_with_path(name):\n",
    "    base_path = './card_images/'\n",
    "    path = os.path.join(base_path, name)\n",
    "    \n",
    "    # Check if the directory already exists\n",
    "    if os.path.exists(path):\n",
    "        # If it exists, remove it and its contents\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "    # Create the new directory\n",
    "    os.makedirs(path)\n",
    "    \n",
    "def generate_random_name(length=8):\n",
    "    # Define a pool of characters to choose from\n",
    "    characters = string.ascii_letters + string.digits\n",
    "\n",
    "    # Generate a random name by selecting characters randomly\n",
    "    random_name = ''.join(random.choice(characters) for _ in range(length))\n",
    "\n",
    "    return random_name\n",
    "\n",
    "        \n",
    "def extract_face_from_card(path_to_img):\n",
    "    img = cv2.imread(path_to_img)\n",
    "    # Extract segmented ID Card\n",
    "    card_cropped = crop_card(img)\n",
    "    # Flip the card\n",
    "    card_flipped = card_flipper(card_cropped)\n",
    "\n",
    "    name = generate_random_name()\n",
    "    create_directory_with_path(name)\n",
    "\n",
    "    cv2.imwrite(f\"./card_images/{name}/{name}.jpg\", card_flipped )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_images/msg-1002053127537-16.jpg\n",
      "\n",
      "0: 640x512 1 0, 1760.0ms\n",
      "Speed: 4.3ms preprocess, 1760.0ms inference, 11.2ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 416x640 1 f-f, 863.2ms\n",
      "Speed: 2.1ms preprocess, 863.2ms inference, 3.8ms postprocess per image at shape (1, 3, 416, 640)\n",
      "z43V9Tnf\n",
      "[[[176 164 154]\n",
      "  [176 164 154]\n",
      "  [176 164 154]\n",
      "  ...\n",
      "  [157 151 146]\n",
      "  [158 152 147]\n",
      "  [160 154 149]]\n",
      "\n",
      " [[176 164 154]\n",
      "  [176 164 154]\n",
      "  [176 164 154]\n",
      "  ...\n",
      "  [142 136 131]\n",
      "  [145 136 132]\n",
      "  [144 138 133]]\n",
      "\n",
      " [[178 166 156]\n",
      "  [178 166 156]\n",
      "  [178 166 156]\n",
      "  ...\n",
      "  [144 136 129]\n",
      "  [146 136 129]\n",
      "  [145 137 130]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[198 194 193]\n",
      "  [198 194 193]\n",
      "  [198 194 193]\n",
      "  ...\n",
      "  [173 161 157]\n",
      "  [169 157 153]\n",
      "  [177 165 161]]\n",
      "\n",
      " [[198 194 193]\n",
      "  [200 196 195]\n",
      "  [200 196 195]\n",
      "  ...\n",
      "  [168 155 153]\n",
      "  [169 157 155]\n",
      "  [170 158 156]]\n",
      "\n",
      " [[198 194 193]\n",
      "  [200 196 195]\n",
      "  [200 196 195]\n",
      "  ...\n",
      "  [171 158 156]\n",
      "  [169 157 155]\n",
      "  [168 156 154]]]\n",
      "raw_images/msg-1002136479675-1358.jpg\n",
      "\n",
      "0: 640x288 1 0, 1343.2ms\n",
      "Speed: 1.7ms preprocess, 1343.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 288)\n",
      "\n",
      "0: 416x640 1 n-f, 1052.2ms\n",
      "Speed: 2.0ms preprocess, 1052.2ms inference, 2.6ms postprocess per image at shape (1, 3, 416, 640)\n",
      "BB0KqFoU\n",
      "[[[ 96  89  96]\n",
      "  [ 95  88  95]\n",
      "  [ 96  89  96]\n",
      "  ...\n",
      "  [ 95  89  94]\n",
      "  [ 89  85  90]\n",
      "  [ 86  82  87]]\n",
      "\n",
      " [[107 100 107]\n",
      "  [103  96 103]\n",
      "  [ 97  90  97]\n",
      "  ...\n",
      "  [ 98  92  97]\n",
      "  [ 91  87  92]\n",
      "  [ 87  83  88]]\n",
      "\n",
      " [[105  99 104]\n",
      "  [101  95 100]\n",
      "  [ 96  90  95]\n",
      "  ...\n",
      "  [101  96  98]\n",
      "  [ 94  89  91]\n",
      "  [ 88  83  85]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 86  90  85]\n",
      "  [ 85  91  86]\n",
      "  [ 89  93  88]\n",
      "  ...\n",
      "  [112 117 116]\n",
      "  [110 112 112]\n",
      "  [ 94  96  96]]\n",
      "\n",
      " [[ 83  88  86]\n",
      "  [ 84  91  88]\n",
      "  [ 87  92  90]\n",
      "  ...\n",
      "  [114 118 119]\n",
      "  [108 113 112]\n",
      "  [ 98 103 102]]\n",
      "\n",
      " [[ 81  88  85]\n",
      "  [ 83  90  87]\n",
      "  [ 85  92  89]\n",
      "  ...\n",
      "  [104 108 109]\n",
      "  [ 96 101 100]\n",
      "  [ 88  93  92]]]\n",
      "raw_images/msg-1002136479675-1354.jpg\n",
      "\n",
      "0: 288x640 1 0, 1404.8ms\n",
      "Speed: 1.6ms preprocess, 1404.8ms inference, 3.7ms postprocess per image at shape (1, 3, 288, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;28mlen\u001b[39m(files_list)):\n",
      "\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(files_list[i])\n",
      "\u001b[0;32m----> 3\u001b[0m     \u001b[43mextract_face_from_card\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[29], line 199\u001b[0m, in \u001b[0;36mextract_face_from_card\u001b[0;34m(path_to_img)\u001b[0m\n",
      "\u001b[1;32m    197\u001b[0m card_cropped \u001b[38;5;241m=\u001b[39m crop_card(img)\n",
      "\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Flip the card\u001b[39;00m\n",
      "\u001b[0;32m--> 199\u001b[0m card_flipped \u001b[38;5;241m=\u001b[39m \u001b[43mcard_flipper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcard_cropped\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    201\u001b[0m name \u001b[38;5;241m=\u001b[39m generate_random_name()\n",
      "\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n",
      "\n",
      "Cell \u001b[0;32mIn[29], line 156\u001b[0m, in \u001b[0;36mcard_flipper\u001b[0;34m(img)\u001b[0m\n",
      "\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcard_flipper\u001b[39m(img):\n",
      "\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n",
      "\u001b[0;32m--> 156\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mflipping_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    157\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxywh\u001b[38;5;66;03m# Assuming the boxes are in xywh format\u001b[39;00m\n",
      "\u001b[1;32m    158\u001b[0m     classes \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mcls\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/model.py:102\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the predict() method with given arguments to perform object detection.\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/model.py:275\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n",
      "\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n",
      "\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/predictor.py:204\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n",
      "\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n",
      "\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/predictor.py:283\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n",
      "\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[0;32m--> 283\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n",
      "\u001b[1;32m    285\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/engine/predictor.py:140\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n",
      "\u001b[1;32m    135\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[1;32m    136\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n",
      "\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;32m    139\u001b[0m )\n",
      "\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:384\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n",
      "\u001b[1;32m    381\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n",
      "\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n",
      "\u001b[0;32m--> 384\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n",
      "\u001b[1;32m    386\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:80\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n",
      "\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:98\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n",
      "\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n",
      "\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n",
      "\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/nn/tasks.py:119\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n",
      "\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n",
      "\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n",
      "\u001b[0;32m--> 119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n",
      "\u001b[1;32m    120\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n",
      "\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:222\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[1;32m    220\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;32m    221\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n",
      "\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range (len(files_list)):\n",
    "    extract_face_from_card(files_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
